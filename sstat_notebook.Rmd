---
title: "Paleo superstatistics notebook"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
```

## Getting the data

### PBDB API

To obtain the PBDB data we make use of the API in script `data/pbdb_data_get.R`, which accesses the API and cleans the data by:

- removing poorly lithified specimens
- removing collections at the basin scale
- including only fine-scale stratigraphy (below the "group" level)
- resolving taxonomy to the genus or subgenus level where availible (storing genus or subgenus as `otu`)
- combining multiple records of the same OTU per collection
- importing standardized timebins from \url{fossilworks.org} (timebins are scraped with script `data/fossilworks_tbins_intervals.R`)

The data gathering script `data/pbdb_data_get.R` is shown below:

```{r code=readLines('data/pbdb_data_get.R')}
```


### Scraping fossilworks

The script to pull Alory's time bins (`data/fossilworks_tbins_intervals.R`) is below: 

```{r code=readLines('data/fossilworks_tbins_intervals.R')}
```


## Three timer and publication bias correction

Once the data have been downloaded and cleaned, we correct for incomplete and biased sampling with the script `data/pbdb_3TPub_make.R` which sources the function `R/make3TPub.R` to generate the main output: a matrix with time bins as rows, taxa (families in this case) as columns and bias-corrected richness as cells.

```{r code=readLines('data/pbdb_3TPub_make.R')}
```

Here is the guts of the `make3TPub` function
```{r code=readLines('R/make3TPub.R')}
```


Our publication correction is simple: we take the exponential of the residual of this relationship:
$$
\text{log(3T-corrected richness)} = \beta_0 + \beta_1 \text{log(number of publications)} + \epsilon
$$
The exponentiated residual amounts to dividing the three-timer corrected richness by a publication correction factor: $\text{(3T-corrected richness)} / e^{\hat{y}}$ where $\hat{y}$ is the predicted trend line from the above relationship.

So we can use this multiplicative publication correction factor in addition to the similarely multiplicative three-timer correction to bias-correct individual genus-level occurrences. This is important when we permute these bias-corrected genera across families to create a null set of d-statistics for our superstatistical fit.


We can check our correction against other popular methods.  In the script `analysis/pbdb_divCurve.R` we specifically compare simple rarifaction, with the SQS method, with our three-time and publication bias correction methods.  All these various methods have close agreement.  The script `analysis/pbdb_divCurve.R` is shown below:

```{r code=readLines('analysis/pbdb_divCurve.R')}
```


## Super statistical analysis of 3TPub-corrected PBDB data

Once data have been bias-corrected we can complete their super-statistical analysis.  We do that in the script `analysis/pbdb_sstat.R` shown here:

```{r code=readLines('analysis/pbdb_sstat.R')}
```


Now we can calculate a measure of goodness of fit with the Komolgorov-Smirnov test statistics $D$. That is done in the script `analysis/pbdb_dperm.R`. This script uses a permutational approach to create a null distribution of test statistics.  The goal is to see if the good fit of super-statistics at the family and order levels is purely from the number of different groupings at those levels, regardless of the biology that might be going on to make those levels actually mechanistically meaningful.  So to achieve such a null, we permute orders across families, calculate the D-statistics of those permuted groupings, and compare to the real D-statistics from the actual biological groupings.  The script is shown below:

```{r code=readLines('analysis/pbdb_dperm.R')}
```


This permutational null test is in part motivated by the correlation between the genus richness of a family and its $\beta_k$ value.  We demonstrate this correlation in the script `analysis/pbdb_betaRichness.R` which is reproduced below:

```{r code=readLines('analysis/pbdb_betaRichness.R')}
```


Now that we are reasonably convinced that these superstatistical findings are not just an artifact of taxonomy or clade size, we can explore why we see deviations from super statistics with increasing taxonomic level. We first explore how well the Gaussian $p_k(x | \beta_k)$ fit at each taxonomic level in the script `analysis/pkx_diffK.R` shown here:

```{r code=readLines('analysis/pkx_diffK.R')}
```

We can also explore how well the $f(\beta_k)$ fit at different taxonomic levels in the script `analysis/pbeta_diffK.R` reproduced below:

```{r code=readLines('analysis/pbeta_diffK.R')}
```


Part of our argument about the failure of superstatistics at higher taxonomic levels is that these higher taxa aggregate increasingly disperate subtaxa.  To investigate this idea we look at the number of guilds represented by the average taxon at each taxonomic level in the script `analysis/pbdb_ecoEvoSpace.R` shown here:

```{r code=readLines('analysis/pbdb_ecoEvoSpace.R')}
```


## Helper functions

All the above analyses make use of helpful functions in the `R` directory. We reproduce those functions below:

```{r code=readLines('R/calcFlux.R')}
```

```{r code=readLines('R/gammaLS.R')}
```

```{r code=readLines('R/make3TPub.R')}
```

```{r code=readLines('R/normLS.R')}
```

```{r code=readLines('R/Px_gam.R')}
```

```{r code=readLines('R/sstat_likelihood_methods.R')}
```

```{r code=readLines('R/sstat_plot_methods.R')}
```

```{r code=readLines('R/sstatComp.R')}
```
