---
title: "Paleo superstatistics notebook"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
```

## Getting the data

### PBDB API

To obtain the PBDB data we make use of the API in script `data/pbdb_data_get.R`, which accesses the API and cleans the data by:

- removing poorly lithified specimens
- removing collections at the basin scale
- including only fine-scale stratigraphy (below the "group" level)
- resolving taxonomy to the genus or subgenus level where availible (storing genus or subgenus as `otu`)
- combining multiple records of the same OTU per collection
- importing standardized timebins from \url{fossilworks.org} (timebins are scraped with script `data/fossilworks_tbins_intervals.R`)

The data gathering script `data/pbdb_data_get.R` is shown below:

```{r code=readLines('data/pbdb_data_get.R')}
```


### Scraping fossilworks

The script to pull Alory's time bins (`data/fossilworks_tbins_intervals.R`) is below: 

```{r code=readLines('data/fossilworks_tbins_intervals.R')}
```


## Three timer and publication bias correction

Once the data have been downloaded and cleaned, we correct for incomplete and biased sampling with the script `data/pbdb_3TPub_make.R` which sources the function `R/make3TPub.R` to generate the main output: a matrix with time bins as rows, taxa (families in this case) as columns and bias-corrected richness as cells.

```{r code=readLines('data/pbdb_3TPub_make.R')}
```

Here is the guts of the `make3TPub` function
```{r code=readLines('R/make3TPub.R')}
```


Our publication correction is simple: we take the exponential of the residual of this relationship:
$$
\text{log(3T-corrected richness)} = \beta_0 + \beta_1 \text{log(number of publications)} + \epsilon
$$
The exponentiated residual amounts to dividing the three-timer corrected richness by a publication correction factor: $\text{(3T-corrected richness)} / e^{\hat{y}}$ where $\hat{y}$ is the predicted trend line from the above relationship.

So we can use this multiplicative publication correction factor in addition to the similarely multiplicative three-timer correction to bias-correct individual genus-level occurrences. This is important when we permute these bias-corrected genera across families to create a null set of d-statistics for our superstatistical fit.


## Super statistical analysis of 3TPub-corrected PBDB data

Once data have been bias-corrected we can complete their super-statistical analysis.  We do that in the script `analysis/pbdb_sstat.R` shown here:

```{r code=readLines('analysis/pbdb_sstat.R')}
```


Now we can calculate a measure of goodness of fit with the Komolgorov-Smirnov test statistics $D$. That is done in the script `analysis/pbdb_dperm.R`. This script uses a permutational approach to create a null distribution of test statistics.  The goal is to see if the good fit of super-statistics at the family and order levels is purely from the number of different groupings at those levels, regardless of the biology that might be going on to make those levels actually mechanistically meaningful.  So to achieve such a null, we permute orders across families, calculate the D-statistics of those permuted groupings, and compare to the real D-statistics from the actual biological groupings.  The script is shown below:

```{r code=readLines('analysis/pbdb_dperm.R')}
```

## To-do

- remove all deprecated files and folders...do it in one fell swoop so we can roll back if needed ever
- run clean functions on sepkoski
- manuscript text
    - add more recent citations
    - add more thurough explaination and justification of correction approach 
    - respond to other reviewer comments

